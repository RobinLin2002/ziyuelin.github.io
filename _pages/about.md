---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I received my B.S. from The Chinese University of Hong Kong, Shenzhen. I am currently pursuing a master's degree in the Department of Mathematics at The University of Hong Kong, with a major in Artificial Intelligence. **I am currently seeking PhD positions for 2026 Fall.**

My research interests include computer vision, image restoration, and interpretability in AI.

I am very fortunate to be advised by [Prof. Qu](https://liangqiong.github.io/) from [School of Computing and Data Science](https://www.cds.hku.hk/), The University of Hong Kong.


# 🔥 News
- *2025.04*: &nbsp;🎉🎉 FedVLMBench was submitted to Neurips-2025.
- *2025.04*: &nbsp;🎉🎉 Started working on diffusion and image restoration.
- *2025.03*: &nbsp;🎉🎉 One paper was submitted to ICCV-2025.
- *2024.10*: &nbsp;🎉🎉 MLLM-Bench was accepted by NAACL-2025!
- *2024.09*: &nbsp;🎉🎉 Started learning at HKU.

# 📝 Publications & Pre-prints

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">CVPR 2016</div>
      <img src='images/FedVLMBench.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">
    [FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models](https://www.arxiv.org/pdf/2506.09638)
    
    Weiying Zheng, <strong>Ziyue Lin</strong>, Pengxin Guo, Yuyin Zhou, Feifei Wang, Liangqiong Qu
    
    [<strong>Project</strong>](https://example.com) <strong><span class='show_paper_citations' data='example'></span></strong>
    - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum.
  </div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">ICCV 2025</div>
      <img src='images/ARRA.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">
    [Unleashing the Potential of Large Language Models for Text-to-Image Generation through Autoregressive Representation Alignment](https://example.com)
    
    Xing Xie, Jiawei Liu, <strong>Ziyue Lin</strong>, Huijie Fan, Zhi Han, Yandong Tang, Liangqiong Qu
    
    [<strong>Project</strong>](https://example.com) <strong><span class='show_paper_citations' data='example'></span></strong>
    - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum.
  </div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">NAACL 2025</div>
      <img src='images/MLLM-Bench.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">
    [MLLM-Bench, Evaluating Multi-modal LLMs using GPT-4V](https://aclanthology.org/2025.naacl-long.256.pdf)
    
    Wentao Ge∗, Shunian Chen∗, Guiming Hardy Chen*, Nuo Chen, Junying Chen, Zhihong Chen†, Wenya Xie, Shuo Yan, Chenghao Zhu, <strong>Ziyue Lin</strong>, Dingjie Song, Xidong Wang, Anningzhe Gao, Zhiyi Zhang, Jianquan Li, Xiang Wan, Benyou Wang†
    
    [<strong>Project</strong>](https://example.com) <strong><span class='show_paper_citations' data='example'></span></strong>
    - Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum.
  </div>
</div>

<style>
  .paper-box {
    display: flex;
    margin-bottom: 30px;
    border: 1px solid #eee;
    border-radius: 4px;
    overflow: hidden;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
  }
  .paper-box-image {
    flex: 0 0 30%;
    position: relative;
  }
  .paper-box-text {
    flex: 1;
    padding: 15px;
    font-size: 16px;
    line-height: 1.6;
  }
  .paper-box-text a {
    color: #0366d6;
    text-decoration: none;
  }
  .paper-box-text a:hover {
    text-decoration: underline;
  }
  .paper-box-text strong {
    font-weight: 600;
  }
  .badge {
    position: absolute;
    top: 10px;
    left: 10px;
    background-color: #ff6b6b;
    color: white;
    padding: 3px 8px;
    border-radius: 3px;
    font-size: 12px;
    font-weight: bold;
  }
</style>







[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 


- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# 🎖 Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 📖 Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# 💻 Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
